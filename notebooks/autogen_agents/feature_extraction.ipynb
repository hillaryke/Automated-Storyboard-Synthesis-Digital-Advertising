{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "PROJECT_PATH = os.environ.get('PROJECT_PATH')\n",
    "\n",
    "# Add the project root path to sys.path\n",
    "if PROJECT_PATH not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.image_composition import compose_ad_frame\n",
    "from src.feature_extraction import extract_text_with_positions, has_transparency, get_image_dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test compose ad frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "composed_image_frame.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "game_id = \"0a22f881b77f00220f2034c21a18b854\"\n",
    "assets_path = os.path.join(PROJECT_PATH, 'data', 'Assets', game_id)\n",
    "\n",
    "# Example usage\n",
    "# assets_path = '/path/to/assets'\n",
    "elements = [\n",
    "    {'image_path': f'{assets_path}/header.jpg', 'position': (0, 0), 'has_background': True},\n",
    "    {'image_path': f'{assets_path}/engagement_instruction_1.png', 'position': (40, 100), 'has_background': False},\n",
    "    {'image_path': f'{assets_path}/thumbnail.jpg', 'position': (0, 200), 'size': get_image_dimensions(f'{assets_path}/thumbnail.jpg'), 'has_background': True}\n",
    "]\n",
    "\n",
    "composed_frame = compose_ad_frame(600, 500, elements)\n",
    "# composed_frame.show()  # Or save using composed_frame.save('composed_frame.jpg')\n",
    "print(composed_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 200)\n",
      "False\n",
      "{'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}\n"
     ]
    }
   ],
   "source": [
    "image_path = f'{assets_path}/header.jpg'\n",
    "print(get_image_dimensions(image_path))\n",
    "print(has_transparency(image_path))\n",
    "print(extract_text_with_positions(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_combine_text(data):\n",
    "  \"\"\"\n",
    "  Extracts text from the 'text_in_image_with_location' key within a dictionary\n",
    "  and attempts to combine them into a sentence, handling potential missing data.\n",
    "\n",
    "  Args:\n",
    "      data: A dictionary containing text information.\n",
    "\n",
    "  Returns:\n",
    "      A string representing the combined text or an empty string if no text is found.\n",
    "  \"\"\"\n",
    "  text_list = []\n",
    "  for key, value in data.items():\n",
    "    # Check if 'text_in_image_with_location' exists and has a value\n",
    "    if 'text_in_image_with_location' in value and value['text_in_image_with_location']:\n",
    "      text_list.extend(value['text_in_image_with_location'].keys())\n",
    "    # Alternatively, use get method with a default empty dictionary\n",
    "    # text_list.extend(value.get('text_in_image_with_location', {}).keys())\n",
    "  return \" \".join(text_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'header': {'image': 'header', 'dimensions': (600, 200), 'text_in_image_with_location': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}, 'has_transparency': False}, 'engagement_instruction': {'image': 'engagement_instruction', 'dimensions': (380, 63), 'text_in_image_with_location': {'TAP': (0, 1, 64, 28), 'THE': (75, 1, 140, 28), 'SCREEN': (152, 0, 293, 29), 'to': (0, 40, 21, 58), 'find': (27, 36, 65, 58), 'the': (73, 36, 106, 58), 'nearest': (114, 40, 192, 58), 'Lexus': (200, 36, 261, 58), 'dealership': (268, 36, 380, 63)}, 'has_transparency': True}, 'thumbnail': {'image': 'thumbnail', 'dimensions': (600, 300), 'text_in_image_with_location': {}, 'has_transparency': False}}\n"
     ]
    }
   ],
   "source": [
    "def get_assets_features(image_path: str, image_role: str) -> dict:\n",
    "    return {\n",
    "        'image': image_role,\n",
    "        # 'image_path': image_path,\n",
    "        \"dimensions\": get_image_dimensions(image_path),\n",
    "        'text_in_image_with_location': extract_text_with_positions(image_path),\n",
    "        'has_transparency': has_transparency(image_path)\n",
    "    }\n",
    "    \n",
    "# print(get_assets_features(image_path, 'header'))\n",
    "assets_inputs = {\n",
    "    \"header\": f'{assets_path}/header.jpg',\n",
    "    \"engagement_instruction\": f'{assets_path}/engagement_instruction_1.png',\n",
    "    \"thumbnail\": f'{assets_path}/thumbnail.jpg'\n",
    "}\n",
    "\n",
    "all_assets_features = {image_role: get_assets_features(image_path, image_role) for image_role, image_path in assets_inputs.items()}\n",
    "print(all_assets_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### More dynamic way to extract text from image\n",
    "def get_frame_features(frame_path: str, assets_path: str) -> dict:\n",
    "  frame_features = {\n",
    "    \"frame_path\": frame_path,\n",
    "    \"ad_frame_dimensions\": (600, 500),\n",
    "    'text_bounded_box_format': (\"left\", \"top\", \"right\", \"bottom\"),\n",
    "    'text_bounding_boxes': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90), 'TAP': (1, 101, 65, 128), 'THE': (76, 101, 141, 128), 'SCREEN': (153, 100, 294, 129), 'to': (1, 140, 22, 158), 'find': (28, 136, 66, 158), 'the': (74, 136, 107, 158), 'nearest': (115, 140, 193, 158), 'Lexus': (201, 136, 262, 158), 'dealership': (269, 136, 381, 163)},\n",
    "    \"elements\": {\n",
    "        \"header\": {\n",
    "          'image_path': f'{assets_path}/header.jpg', \n",
    "          'position': (0, 0),\n",
    "          'size': (600, 200),\n",
    "          'text_in_image': ['Ovexus', 'L/CERTIFIED', 'BY', 'LEXUS'],\n",
    "          'has_background': True\n",
    "        },\n",
    "        \"engagement_instruction\": {\n",
    "          'image_path': f'{assets_path}/engagement_instruction_1.png', \n",
    "          'position': (0, 100),\n",
    "          'size': (380, 63),\n",
    "          'text_in_image': ['TAP', 'THE', 'SCREEN', 'to', 'find', 'the', 'nearest', 'Lexus', 'dealership'],\n",
    "          'has_background': False\n",
    "        },\n",
    "        \"thubmnail\": {\n",
    "          'image_path': f'{assets_path}/thumbnail.jpg', \n",
    "          'position': (0, 200), \n",
    "          'size': (600, 300),\n",
    "          'text_in_image': {},\n",
    "          'has_background': True\n",
    "        }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return {\n",
    "    \"frame_features\": frame_features\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header dims: 600x200. header_text: Ovexus: 50,27,245,60; L/CERTIFIED: 50,77,161,90; BY: 174,77,198,90; LEXUS: 211,77,283,90. engagement_instruction dims: 380x63. engagement_instruction_text: TAP: 0,1,64,28; THE: 75,1,140,28; SCREEN: 152,0,293,29; to: 0,40,21,58; find: 27,36,65,58; the: 73,36,106,58; nearest: 114,40,192,58; Lexus: 200,36,261,58; dealership: 268,36,380,63. thumbnail dims: 600x300\n"
     ]
    }
   ],
   "source": [
    "def summarize_output_data(output_data):\n",
    "    \"\"\"\n",
    "    Summarizes the output data by extracting key information and formatting it into a concise string.\n",
    "\n",
    "    Args:\n",
    "        output_data (dict): The output data containing text information and dimensions.\n",
    "\n",
    "    Returns:\n",
    "        str: A summarized string of the output data.\n",
    "    \"\"\"\n",
    "    summary_parts = []\n",
    "\n",
    "    for section, content in output_data.items():\n",
    "        if 'dimensions' in content:\n",
    "            dims = 'x'.join(map(str, content['dimensions']))\n",
    "            summary_parts.append(f\"{section} dims: {dims}\")\n",
    "\n",
    "        if 'text_in_image_with_location' in content and content['text_in_image_with_location']:\n",
    "            text_summary = '; '.join([f\"{text}: {','.join(map(str, loc))}\" for text, loc in content['text_in_image_with_location'].items()])\n",
    "            summary_parts.append(f\"{section}_text: {text_summary}\")\n",
    "\n",
    "    return '. '.join(summary_parts)\n",
    "\n",
    "# Example usage\n",
    "output_data = {\n",
    "    'header': {'image': 'header', 'dimensions': (600, 200), 'text_in_image_with_location': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}, 'has_transparency': False}, \n",
    "    'engagement_instruction': {'image': 'engagement_instruction', 'dimensions': (380, 63), 'text_in_image_with_location': {'TAP': (0, 1, 64, 28), 'THE': (75, 1, 140, 28), 'SCREEN': (152, 0, 293, 29), 'to': (0, 40, 21, 58), 'find': (27, 36, 65, 58), 'the': (73, 36, 106, 58), 'nearest': (114, 40, 192, 58), 'Lexus': (200, 36, 261, 58), 'dealership': (268, 36, 380, 63)}, 'has_transparency': True}, \n",
    "    'thumbnail': {'image': 'thumbnail', 'dimensions': (600, 300), 'text_in_image_with_location': {}, 'has_transparency': False}\n",
    "}\n",
    "\n",
    "summary = summarize_output_data(output_data)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
