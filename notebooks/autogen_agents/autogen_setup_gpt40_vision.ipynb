{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, AssistantAgent, GroupChatManager, GroupChat, UserProxyAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "PROJECT_PATH = os.environ.get('PROJECT_PATH')\n",
    "\n",
    "# Add the project root path to sys.path\n",
    "if PROJECT_PATH not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.image_composition import compose_ad_frame\n",
    "from src.feature_extraction import extract_text_with_positions, has_transparency, get_image_dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test compose ad frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "composed_image_frame.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "game_id = \"0a22f881b77f00220f2034c21a18b854\"\n",
    "assets_path = os.path.join(PROJECT_PATH, 'data', 'Assets', game_id)\n",
    "\n",
    "# Example usage\n",
    "# assets_path = '/path/to/assets'\n",
    "elements = [\n",
    "    {'image_path': f'{assets_path}/header.jpg', 'position': (0, 0), 'has_background': True},\n",
    "    {'image_path': f'{assets_path}/engagement_instruction_1.png', 'position': (40, 100), 'has_background': False},\n",
    "    {'image_path': f'{assets_path}/thumbnail.jpg', 'position': (0, 200), 'size': get_image_dimensions(f'{assets_path}/thumbnail.jpg'), 'has_background': True}\n",
    "]\n",
    "\n",
    "composed_frame = compose_ad_frame(600, 500, elements)\n",
    "# composed_frame.show()  # Or save using composed_frame.save('composed_frame.jpg')\n",
    "print(composed_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define image composition agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4o\",  # Specifies the model version to be used\n",
    "        \"temperature\": 0.7,  # Keeps the creativity level\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "llm_config_img_composition = {\n",
    "    \"model\": \"gpt-4o\", # Updated to the latest model version\n",
    "    \"temperature\": 0.7,  # Keeps the creativity level\n",
    "     \"config_list\": config_list,  # References the LLM configuration defined above\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"compose_ad_frame\",\n",
    "            \"description\": \"Composes an advertisement frame using multiple image elements.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"frame_width\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Width of the desired frame.\"\n",
    "                    },\n",
    "                    \"frame_height\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Height of the desired frame.\"\n",
    "                    },\n",
    "                    \"elements\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"image_path\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"Path to the image file.\"\n",
    "                                },\n",
    "                                \"position\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"integer\"\n",
    "                                    },\n",
    "                                    \"minItems\": 2,\n",
    "                                    \"maxItems\": 2,\n",
    "                                    \"description\": \"(x, y) coordinates of the top-left corner.\"\n",
    "                                },\n",
    "                                \"size\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"integer\"\n",
    "                                    },\n",
    "                                    \"minItems\": 2,\n",
    "                                    \"maxItems\": 2,\n",
    "                                    \"description\": \"(width, height) to resize to (maintaining aspect ratio), optional.\"\n",
    "                                },\n",
    "                                \"has_background\": {\n",
    "                                    \"type\": \"boolean\",\n",
    "                                    \"description\": \"Whether the image has a background (True) or is transparent (False), optional.\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"image_path\", \"position\"]\n",
    "                        },\n",
    "                        \"description\": \"List of dictionaries, each containing details about the image to be composed.\"\n",
    "                    },\n",
    "                    \"output_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Path to save the composed ad frame, optional.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"frame_width\", \"frame_height\", \"elements\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "# Let's first define the assistant agent that suggests tool calls.\n",
    "image_composition_agent = AssistantAgent(\n",
    "    name=\"image_composition_agent\",\n",
    "    system_message=\"\"\"You are a helpful AI assistant.\n",
    "    You task is to compose an AD Frame for StoryBoard using given assets to create an engaging advertisement.\n",
    "    You are to use the 'compose_ad_frame' function to achieve this given the concept and assets details.\n",
    "    Return 'TERMINATE' when the task is done.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config_img_composition,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get frame features function result example (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_frame_features(frame_path: str, assets_path: str) -> dict:\n",
    "#   frame_features = {\n",
    "#     \"frame_path\": frame_path,\n",
    "#     \"ad_frame_dimensions\": (600, 500),\n",
    "#     'text_bounded_box_format': (\"left\", \"top\", \"right\", \"bottom\"),\n",
    "#     'text_bounding_boxes': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90), 'TAP': (1, 101, 65, 128), 'THE': (76, 101, 141, 128), 'SCREEN': (153, 100, 294, 129), 'to': (1, 140, 22, 158), 'find': (28, 136, 66, 158), 'the': (74, 136, 107, 158), 'nearest': (115, 140, 193, 158), 'Lexus': (201, 136, 262, 158), 'dealership': (269, 136, 381, 163)},\n",
    "#     \"elements\": {\n",
    "#         \"header\": {\n",
    "#           'image_path': f'{assets_path}/header.jpg', \n",
    "#           'position': (0, 0),\n",
    "#           'size': (600, 200),\n",
    "#           'text_in_image': ['Ovexus', 'L/CERTIFIED', 'BY', 'LEXUS'],\n",
    "#           'has_background': True\n",
    "#         },\n",
    "#         \"engagement_instruction\": {\n",
    "#           'image_path': f'{assets_path}/engagement_instruction_1.png', \n",
    "#           'position': (0, 100),\n",
    "#           'size': (380, 63),\n",
    "#           'text_in_image': ['TAP', 'THE', 'SCREEN', 'to', 'find', 'the', 'nearest', 'Lexus', 'dealership'],\n",
    "#           'has_background': False\n",
    "#         },\n",
    "#         \"thubmnail\": {\n",
    "#           'image_path': f'{assets_path}/thumbnail.jpg', \n",
    "#           'position': (0, 200), \n",
    "#           'size': (600, 300),\n",
    "#           'text_in_image': {},\n",
    "#           'has_background': True\n",
    "#         }\n",
    "#     }\n",
    "#   }\n",
    "  \n",
    "#   return {\n",
    "#     \"frame_features\": frame_features\n",
    "#   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### More dynamic way to extract text from image\n",
    "def get_frame_features(frame_path: str, assets_path: str) -> dict:\n",
    "  frame_features = {\n",
    "    \"frame_path\": frame_path,\n",
    "    \"ad_frame_dimensions\": (600, 500),\n",
    "    'text_bounded_box_format': (\"left\", \"top\", \"right\", \"bottom\"),\n",
    "    'text_bounding_boxes': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90), 'TAP': (1, 101, 65, 128), 'THE': (76, 101, 141, 128), 'SCREEN': (153, 100, 294, 129), 'to': (1, 140, 22, 158), 'find': (28, 136, 66, 158), 'the': (74, 136, 107, 158), 'nearest': (115, 140, 193, 158), 'Lexus': (201, 136, 262, 158), 'dealership': (269, 136, 381, 163)},\n",
    "    \"elements\": {\n",
    "        \"header\": {\n",
    "          'image_path': f'{assets_path}/header.jpg', \n",
    "          'position': (0, 0),\n",
    "          'size': (600, 200),\n",
    "          'text_in_image': ['Ovexus', 'L/CERTIFIED', 'BY', 'LEXUS'],\n",
    "          'has_background': True\n",
    "        },\n",
    "        \"engagement_instruction\": {\n",
    "          'image_path': f'{assets_path}/engagement_instruction_1.png', \n",
    "          'position': (0, 100),\n",
    "          'size': (380, 63),\n",
    "          'text_in_image': ['TAP', 'THE', 'SCREEN', 'to', 'find', 'the', 'nearest', 'Lexus', 'dealership'],\n",
    "          'has_background': False\n",
    "        },\n",
    "        \"thubmnail\": {\n",
    "          'image_path': f'{assets_path}/thumbnail.jpg', \n",
    "          'position': (0, 200), \n",
    "          'size': (600, 300),\n",
    "          'text_in_image': {},\n",
    "          'has_background': True\n",
    "        }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return {\n",
    "    \"frame_features\": frame_features\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the critic agent using CV tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_critic = {\n",
    "    \"model\": \"gpt-4o\",  # Specify the model version for the critic\n",
    "    \"temperature\": 0.5,  # Adjust the temperature for evaluation\n",
    "    \"config_list\": config_list,  # Use the same LLM configuration list\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_frame_features\",\n",
    "            \"description\": \"Gets detailed features of the frame using computer vision.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"frame_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Path to the image file.\"\n",
    "                    },\n",
    "                    \"assets_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Path to the assets folder containing the image elements to compose.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"frame_path\", \"assets_path\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "critic_agent = AssistantAgent(\n",
    "    name=\"image_critic_agent\",\n",
    "    system_message=\"\"\"\n",
    "    You are a critic AI agent. \n",
    "    Your task is to evaluate the quality of the composed ad frames. \n",
    "    You will execute function to get frame features that uses Computer vision tools to get the features of the frame.\n",
    "    Check on the design of the frame and the text in the frame, ensure not overlapping, e.t.c and use the best design principles in the critique.\n",
    "    You can check for the alignment of the image and text in the frame to make it more appealing. i.e the logo, slogan and the engagement instruction can be made to start on the same vertical line.\n",
    "    If the frame is not good, suggest the necessary changes in positioning the elements to be made.\n",
    "    If the frame is good, just say 'All good' and return 'TERMINATE' when the evaluation is complete.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config_critic,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define critic agent using GPT-4o vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up configs for groupchat manager and user agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "  \"config_list\": \n",
    "    [\n",
    "      {\"model\": \"gpt-4o\"}\n",
    "    ]\n",
    "  }\n",
    "\n",
    "llm_config_user = {\n",
    "  \"config_list\": \n",
    "    [\n",
    "      {\"model\": \"gpt-3.5-turbo\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User proxy agent setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_user = \"\"\"\n",
    "\"You are a the Human admin in the groupchat. \n",
    "You can interact with the image composition and the critic agents.\n",
    "Execute their recommended functions and return the output as it is to the agents (Do not interpret the results).\n",
    "\"\"\"\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=llm_config_user,\n",
    "    system_message=system_message_user,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    # max_consecutive_auto_reply=3,\n",
    "    function_map={\n",
    "        \"compose_ad_frame\": compose_ad_frame,\n",
    "        \"get_frame_features\": get_frame_features\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup groupchat manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.groupchat import GroupChatManager\n",
    "\n",
    "class CustomGroupChatManager(GroupChatManager):\n",
    "    def _select_next_speaker(self, last_speaker, last_message, groupchat):\n",
    "        # Prioritize image_critic_agent when frame_features are ready\n",
    "        if (last_speaker.name == \"User\" and \n",
    "            \"frame_features\" in last_message.get(\"content\", {}) and \n",
    "            \"image_critic_agent\" in groupchat.agent_names):\n",
    "            return groupchat.agent_by_name(\"image_critic_agent\")\n",
    "\n",
    "        # For all other cases, use default behavior (or your custom logic)\n",
    "        return super()._select_next_speaker(last_speaker, last_message, groupchat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groupchat = GroupChat(agents=[user_proxy, image_composition_agent, critic_agent], messages=[])\n",
    "manager = CustomGroupChatManager(groupchat=groupchat, llm_config=llm_config)  # Use the custom manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 200)\n",
      "False\n",
      "{'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}\n"
     ]
    }
   ],
   "source": [
    "image_path = f'{assets_path}/header.jpg'\n",
    "print(get_image_dimensions(image_path))\n",
    "print(has_transparency(image_path))\n",
    "print(extract_text_with_positions(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_role': 'header', 'dimensions': (600, 200), 'text_in_image_with_location': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}, 'has_transparency': False}\n",
      "{'header': {'image_role': 'header', 'dimensions': (600, 200), 'text_in_image_with_location': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}, 'has_transparency': False}, 'engagement_instruction': {'image_role': 'engagement_instruction', 'dimensions': (380, 63), 'text_in_image_with_location': {'TAP': (0, 1, 64, 28), 'THE': (75, 1, 140, 28), 'SCREEN': (152, 0, 293, 29), 'to': (0, 40, 21, 58), 'find': (27, 36, 65, 58), 'the': (73, 36, 106, 58), 'nearest': (114, 40, 192, 58), 'Lexus': (200, 36, 261, 58), 'dealership': (268, 36, 380, 63)}, 'has_transparency': True}, 'thumbnail': {'image_role': 'thumbnail', 'dimensions': (600, 300), 'text_in_image_with_location': {}, 'has_transparency': False}}\n"
     ]
    }
   ],
   "source": [
    "# def get_assets_features(image_path: str, image_role: str) -> dict:\n",
    "#     return {\n",
    "#         'image_role': image_role,\n",
    "#         \"dimensions\": get_image_dimensions(image_path),\n",
    "#         'text_in_image_with_location': extract_text_with_positions(image_path),\n",
    "#         'has_transparency': has_transparency(image_path)\n",
    "#     }\n",
    "    \n",
    "# print(get_assets_features(image_path, 'header'))\n",
    "assets_inputs = {\n",
    "    \"header\": f'{assets_path}/header.jpg',\n",
    "    \"engagement_instruction\": f'{assets_path}/engagement_instruction_1.png',\n",
    "    \"thumbnail\": f'{assets_path}/thumbnail.jpg'\n",
    "}\n",
    "\n",
    "get_all_assets_features = {image_role: get_assets_features(image_path, image_role) for image_role, image_path in assets_inputs.items()}\n",
    "print(get_all_assets_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_proxy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 21\u001b[0m\n\u001b[1;32m     12\u001b[0m user_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124mCompose an AD Frame with the dimensions 600x500 for StoryBoard\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mThis is the concept. Place the header image at the top-left corner.\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124mPlace the engagement instruction just below the logo in the header image\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124mPlace the thumbnail below the header image.\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     19\u001b[0m final_message \u001b[38;5;241m=\u001b[39m user_message \u001b[38;5;241m+\u001b[39m system_instruction\n\u001b[0;32m---> 21\u001b[0m chat_result \u001b[38;5;241m=\u001b[39m \u001b[43muser_proxy\u001b[49m\u001b[38;5;241m.\u001b[39minitiate_chat(manager, message\u001b[38;5;241m=\u001b[39mfinal_message, max_turns\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_proxy' is not defined"
     ]
    }
   ],
   "source": [
    "assets_path = '/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/'\n",
    "system_instruction = f\"\"\"\n",
    "The path to the assets folder is {assets_path}\n",
    "\n",
    "Use the assets path and the image names to get the image path\n",
    "\n",
    "The output path is the data folder can be derived from assets path with the name composed_image_frame.jpg\n",
    "\n",
    "Return 'TERMINATE' when the task is done.\n",
    "\"\"\"\n",
    "\n",
    "user_message = \"\"\"\n",
    "Compose an AD Frame with the dimensions 600x500 for StoryBoard\n",
    "This is the concept. Place the header image at the top-left corner.\n",
    "Place the engagement instruction just below the logo in the header image\n",
    "Place the thumbnail below the header image.\n",
    "\n",
    "These are the \n",
    "\"\"\"\n",
    "\n",
    "final_message = user_message + system_instruction\n",
    "\n",
    "chat_result = user_proxy.initiate_chat(manager, message=final_message, max_turns=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
