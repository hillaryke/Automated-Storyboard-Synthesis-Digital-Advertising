{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent, AssistantAgent, GroupChatManager, GroupChat, UserProxyAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setup env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "PROJECT_PATH = os.environ.get('PROJECT_PATH')\n",
    "\n",
    "# Add the project root path to sys.path\n",
    "if PROJECT_PATH not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.image_composition import compose_ad_frame\n",
    "from src.feature_extraction import extract_text_with_positions, has_transparency, get_image_dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test compose ad frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "composed_image_frame.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "game_id = \"0a22f881b77f00220f2034c21a18b854\"\n",
    "assets_path = os.path.join(PROJECT_PATH, 'data', 'Assets', game_id)\n",
    "\n",
    "# Example usage\n",
    "# assets_path = '/path/to/assets'\n",
    "elements = [\n",
    "    {'image_path': f'{assets_path}/header.jpg', 'position': (0, 0), 'has_background': True},\n",
    "    {'image_path': f'{assets_path}/engagement_instruction_1.png', 'position': (40, 100), 'has_background': False},\n",
    "    {'image_path': f'{assets_path}/thumbnail.jpg', 'position': (0, 200), 'size': get_image_dimensions(f'{assets_path}/thumbnail.jpg'), 'has_background': True}\n",
    "]\n",
    "\n",
    "composed_frame = compose_ad_frame(600, 500, elements)\n",
    "# composed_frame.show()  # Or save using composed_frame.save('composed_frame.jpg')\n",
    "print(composed_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define image composition agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        \"model\": \"gpt-4o\",  # Specifies the model version to be used\n",
    "        \"temperature\": 0.7,  # Keeps the creativity level\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "llm_config_img_composition = {\n",
    "    \"model\": \"gpt-4o\", # Updated to the latest model version\n",
    "    \"temperature\": 0.7,  # Keeps the creativity level\n",
    "     \"config_list\": config_list,  # References the LLM configuration defined above\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"compose_ad_frame\",\n",
    "            \"description\": \"Composes an advertisement frame using multiple image elements.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"frame_width\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Width of the desired frame.\"\n",
    "                    },\n",
    "                    \"frame_height\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Height of the desired frame.\"\n",
    "                    },\n",
    "                    \"elements\": {\n",
    "                        \"type\": \"array\",\n",
    "                        \"items\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"image_path\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"Path to the image file.\"\n",
    "                                },\n",
    "                                \"position\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"integer\"\n",
    "                                    },\n",
    "                                    \"minItems\": 2,\n",
    "                                    \"maxItems\": 2,\n",
    "                                    \"description\": \"(x, y) coordinates of the top-left corner.\"\n",
    "                                },\n",
    "                                \"size\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"integer\"\n",
    "                                    },\n",
    "                                    \"minItems\": 2,\n",
    "                                    \"maxItems\": 2,\n",
    "                                    \"description\": \"(width, height) to resize to (maintaining aspect ratio), optional.\"\n",
    "                                },\n",
    "                                \"has_background\": {\n",
    "                                    \"type\": \"boolean\",\n",
    "                                    \"description\": \"Whether the image has a background (True) or is transparent (False), optional.\"\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"image_path\", \"position\"]\n",
    "                        },\n",
    "                        \"description\": \"List of dictionaries, each containing details about the image to be composed.\"\n",
    "                    },\n",
    "                    \"output_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Path to save the composed ad frame, optional.\"\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"frame_width\", \"frame_height\", \"elements\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "# Let's first define the assistant agent that suggests tool calls.\n",
    "image_composition_agent = AssistantAgent(\n",
    "    name=\"image_composition_agent\",\n",
    "    system_message=\"\"\"You are a helpful AI assistant.\n",
    "    You task is to compose an AD Frame for StoryBoard using given assets to create an engaging advertisement.\n",
    "    You are to use the 'compose_ad_frame' function to achieve this given the concept and assets details.\n",
    "    Return 'TERMINATE' when the task is done.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config_img_composition,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get frame features function result example (placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_frame_features(frame_path: str, assets_path: str) -> dict:\n",
    "#   frame_features = {\n",
    "#     \"frame_path\": frame_path,\n",
    "#     \"ad_frame_dimensions\": (600, 500),\n",
    "#     'text_bounded_box_format': (\"left\", \"top\", \"right\", \"bottom\"),\n",
    "#     'text_bounding_boxes': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90), 'TAP': (1, 101, 65, 128), 'THE': (76, 101, 141, 128), 'SCREEN': (153, 100, 294, 129), 'to': (1, 140, 22, 158), 'find': (28, 136, 66, 158), 'the': (74, 136, 107, 158), 'nearest': (115, 140, 193, 158), 'Lexus': (201, 136, 262, 158), 'dealership': (269, 136, 381, 163)},\n",
    "#     \"elements\": {\n",
    "#         \"header\": {\n",
    "#           'image_path': f'{assets_path}/header.jpg', \n",
    "#           'position': (0, 0),\n",
    "#           'size': (600, 200),\n",
    "#           'text_in_image': ['Ovexus', 'L/CERTIFIED', 'BY', 'LEXUS'],\n",
    "#           'has_background': True\n",
    "#         },\n",
    "#         \"engagement_instruction\": {\n",
    "#           'image_path': f'{assets_path}/engagement_instruction_1.png', \n",
    "#           'position': (0, 100),\n",
    "#           'size': (380, 63),\n",
    "#           'text_in_image': ['TAP', 'THE', 'SCREEN', 'to', 'find', 'the', 'nearest', 'Lexus', 'dealership'],\n",
    "#           'has_background': False\n",
    "#         },\n",
    "#         \"thubmnail\": {\n",
    "#           'image_path': f'{assets_path}/thumbnail.jpg', \n",
    "#           'position': (0, 200), \n",
    "#           'size': (600, 300),\n",
    "#           'text_in_image': {},\n",
    "#           'has_background': True\n",
    "#         }\n",
    "#     }\n",
    "#   }\n",
    "  \n",
    "#   return {\n",
    "#     \"frame_features\": frame_features\n",
    "#   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### More dynamic way to extract text from image\n",
    "def get_frame_features(frame_path: str, assets_path: str) -> dict:\n",
    "  frame_features = {\n",
    "    \"frame_path\": frame_path,\n",
    "    \"ad_frame_dimensions\": (600, 500),\n",
    "    'text_bounded_box_format': (\"left\", \"top\", \"right\", \"bottom\"),\n",
    "    'text_bounding_boxes': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90), 'TAP': (1, 101, 65, 128), 'THE': (76, 101, 141, 128), 'SCREEN': (153, 100, 294, 129), 'to': (1, 140, 22, 158), 'find': (28, 136, 66, 158), 'the': (74, 136, 107, 158), 'nearest': (115, 140, 193, 158), 'Lexus': (201, 136, 262, 158), 'dealership': (269, 136, 381, 163)},\n",
    "    \"elements\": {\n",
    "        \"header\": {\n",
    "          'image_path': f'{assets_path}/header.jpg', \n",
    "          'position': (0, 0),\n",
    "          'size': (600, 200),\n",
    "          'text_in_image': ['Ovexus', 'L/CERTIFIED', 'BY', 'LEXUS'],\n",
    "          'has_background': True\n",
    "        },\n",
    "        \"engagement_instruction\": {\n",
    "          'image_path': f'{assets_path}/engagement_instruction_1.png', \n",
    "          'position': (0, 100),\n",
    "          'size': (380, 63),\n",
    "          'text_in_image': ['TAP', 'THE', 'SCREEN', 'to', 'find', 'the', 'nearest', 'Lexus', 'dealership'],\n",
    "          'has_background': False\n",
    "        },\n",
    "        \"thubmnail\": {\n",
    "          'image_path': f'{assets_path}/thumbnail.jpg', \n",
    "          'position': (0, 200), \n",
    "          'size': (600, 300),\n",
    "          'text_in_image': {},\n",
    "          'has_background': True\n",
    "        }\n",
    "    }\n",
    "  }\n",
    "  \n",
    "  return {\n",
    "    \"frame_features\": frame_features\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the critic agent using CV tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config_critic = {\n",
    "    \"model\": \"gpt-4o\",  # Specify the model version for the critic\n",
    "    \"temperature\": 0.5,  # Adjust the temperature for evaluation\n",
    "    \"config_list\": config_list,  # Use the same LLM configuration list\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"get_frame_features\",\n",
    "            \"description\": \"Gets detailed features of the frame using computer vision.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"frame_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Path to the image file.\"\n",
    "                    },\n",
    "                    \"assets_path\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Path to the assets folder containing the image elements to compose.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"frame_path\", \"assets_path\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "critic_agent = AssistantAgent(\n",
    "    name=\"image_critic_agent\",\n",
    "    system_message=\"\"\"\n",
    "    You are a critic AI agent. \n",
    "    Your task is to evaluate the quality of the composed ad frames. \n",
    "    You will execute function to get frame features that uses Computer vision tools to get the features of the frame.\n",
    "    If the frame is not good, suggest the necessary changes in positioning the elements to be made.\n",
    "    If the frame is good, just say 'All good' and return 'TERMINATE' when the evaluation is complete.\n",
    "    \n",
    "    These are the design principles to consider:\n",
    "    - Check for balance and organization within the frame.\n",
    "    - Ensure no elements overlap or create unnecessary clutter.\n",
    "    - Consider using white space effectively to guide the viewer's eye.\n",
    "    \"\"\",\n",
    "    llm_config=llm_config_critic,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define critic agent using GPT-4o vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up configs for groupchat manager and user agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_config = {\n",
    "  \"config_list\": \n",
    "    [\n",
    "      {\"model\": \"gpt-4o\"}\n",
    "    ]\n",
    "  }\n",
    "\n",
    "llm_config_user = {\n",
    "  \"config_list\": \n",
    "    [\n",
    "      {\"model\": \"gpt-3.5-turbo\"}\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User proxy agent setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_user = \"\"\"\n",
    "\"You are a the Human admin in the groupchat. \n",
    "You can interact with the image composition and the critic agents.\n",
    "Execute their recommended functions and return the output as it is to the agents (Do not interpret the results).\n",
    "\"\"\"\n",
    "\n",
    "user_proxy = UserProxyAgent(\n",
    "    name=\"User\",\n",
    "    llm_config=llm_config_user,\n",
    "    system_message=system_message_user,\n",
    "    is_termination_msg=lambda msg: msg.get(\"content\") is not None and \"TERMINATE\" in msg[\"content\"],\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config=False,\n",
    "    # max_consecutive_auto_reply=3,\n",
    "    function_map={\n",
    "        \"compose_ad_frame\": compose_ad_frame,\n",
    "        \"get_frame_features\": get_frame_features\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup groupchat manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen.agentchat.groupchat import GroupChatManager\n",
    "\n",
    "class CustomGroupChatManager(GroupChatManager):\n",
    "    def _select_next_speaker(self, last_speaker, last_message, groupchat):\n",
    "        # Prioritize image_critic_agent when frame_features are ready\n",
    "        if (last_speaker.name == \"User\" and \n",
    "            \"frame_features\" in last_message.get(\"content\", {}) and \n",
    "            \"image_critic_agent\" in groupchat.agent_names):\n",
    "            return groupchat.agent_by_name(\"image_critic_agent\")\n",
    "\n",
    "        # For all other cases, use default behavior (or your custom logic)\n",
    "        return super()._select_next_speaker(last_speaker, last_message, groupchat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "groupchat = GroupChat(agents=[user_proxy, image_composition_agent, critic_agent], messages=[])\n",
    "manager = CustomGroupChatManager(groupchat=groupchat, llm_config=llm_config)  # Use the custom manager\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 200)\n",
      "False\n",
      "{'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}\n"
     ]
    }
   ],
   "source": [
    "image_path = f'{assets_path}/header.jpg'\n",
    "print(get_image_dimensions(image_path))\n",
    "print(has_transparency(image_path))\n",
    "print(extract_text_with_positions(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_combine_text(data):\n",
    "  \"\"\"\n",
    "  Extracts text from the 'text_in_image_with_location' key within a dictionary\n",
    "  and attempts to combine them into a sentence, handling potential missing data.\n",
    "\n",
    "  Args:\n",
    "      data: A dictionary containing text information.\n",
    "\n",
    "  Returns:\n",
    "      A string representing the combined text or an empty string if no text is found.\n",
    "  \"\"\"\n",
    "  text_list = []\n",
    "  for key, value in data.items():\n",
    "    # Check if 'text_in_image_with_location' exists and has a value\n",
    "    if 'text_in_image_with_location' in value and value['text_in_image_with_location']:\n",
    "      text_list.extend(value['text_in_image_with_location'].keys())\n",
    "    # Alternatively, use get method with a default empty dictionary\n",
    "    # text_list.extend(value.get('text_in_image_with_location', {}).keys())\n",
    "  return \" \".join(text_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'header': {'image': 'header', 'dimensions': (600, 200), 'text_in_image_with_location': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}, 'has_transparency': False}, 'engagement_instruction': {'image': 'engagement_instruction', 'dimensions': (380, 63), 'text_in_image_with_location': {'TAP': (0, 1, 64, 28), 'THE': (75, 1, 140, 28), 'SCREEN': (152, 0, 293, 29), 'to': (0, 40, 21, 58), 'find': (27, 36, 65, 58), 'the': (73, 36, 106, 58), 'nearest': (114, 40, 192, 58), 'Lexus': (200, 36, 261, 58), 'dealership': (268, 36, 380, 63)}, 'has_transparency': True}, 'thumbnail': {'image': 'thumbnail', 'dimensions': (600, 300), 'text_in_image_with_location': {}, 'has_transparency': False}}\n"
     ]
    }
   ],
   "source": [
    "def get_assets_features(image_path: str, image_role: str) -> dict:\n",
    "    return {\n",
    "        'image': image_role,\n",
    "        # 'image_path': image_path,\n",
    "        \"dimensions\": get_image_dimensions(image_path),\n",
    "        'text_in_image_with_location': extract_text_with_positions(image_path),\n",
    "        'has_transparency': has_transparency(image_path)\n",
    "    }\n",
    "    \n",
    "# print(get_assets_features(image_path, 'header'))\n",
    "assets_inputs = {\n",
    "    \"header\": f'{assets_path}/header.jpg',\n",
    "    \"engagement_instruction\": f'{assets_path}/engagement_instruction_1.png',\n",
    "    \"thumbnail\": f'{assets_path}/thumbnail.jpg'\n",
    "}\n",
    "\n",
    "all_assets_features = {image_role: get_assets_features(image_path, image_role) for image_role, image_path in assets_inputs.items()}\n",
    "print(all_assets_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header dims: 600x200. header_text: Ovexus: 50,27,245,60; L/CERTIFIED: 50,77,161,90; BY: 174,77,198,90; LEXUS: 211,77,283,90. engagement_instruction dims: 380x63. engagement_instruction_text: TAP: 0,1,64,28; THE: 75,1,140,28; SCREEN: 152,0,293,29; to: 0,40,21,58; find: 27,36,65,58; the: 73,36,106,58; nearest: 114,40,192,58; Lexus: 200,36,261,58; dealership: 268,36,380,63. thumbnail dims: 600x300\n"
     ]
    }
   ],
   "source": [
    "def summarize_output_data(output_data):\n",
    "    \"\"\"\n",
    "    Summarizes the output data by extracting key information and formatting it into a concise string.\n",
    "\n",
    "    Args:\n",
    "        output_data (dict): The output data containing text information and dimensions.\n",
    "\n",
    "    Returns:\n",
    "        str: A summarized string of the output data.\n",
    "    \"\"\"\n",
    "    summary_parts = []\n",
    "\n",
    "    for section, content in output_data.items():\n",
    "        if 'dimensions' in content:\n",
    "            dims = 'x'.join(map(str, content['dimensions']))\n",
    "            summary_parts.append(f\"{section} dims: {dims}\")\n",
    "\n",
    "        if 'text_in_image_with_location' in content and content['text_in_image_with_location']:\n",
    "            text_summary = '; '.join([f\"{text}: {','.join(map(str, loc))}\" for text, loc in content['text_in_image_with_location'].items()])\n",
    "            summary_parts.append(f\"{section}_text: {text_summary}\")\n",
    "\n",
    "    return '. '.join(summary_parts)\n",
    "\n",
    "# Example usage\n",
    "output_data = {\n",
    "    'header': {'image': 'header', 'dimensions': (600, 200), 'text_in_image_with_location': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}, 'has_transparency': False}, \n",
    "    'engagement_instruction': {'image': 'engagement_instruction', 'dimensions': (380, 63), 'text_in_image_with_location': {'TAP': (0, 1, 64, 28), 'THE': (75, 1, 140, 28), 'SCREEN': (152, 0, 293, 29), 'to': (0, 40, 21, 58), 'find': (27, 36, 65, 58), 'the': (73, 36, 106, 58), 'nearest': (114, 40, 192, 58), 'Lexus': (200, 36, 261, 58), 'dealership': (268, 36, 380, 63)}, 'has_transparency': True}, \n",
    "    'thumbnail': {'image': 'thumbnail', 'dimensions': (600, 300), 'text_in_image_with_location': {}, 'has_transparency': False}\n",
    "}\n",
    "\n",
    "summary = summarize_output_data(output_data)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-9nAFmCrmSnpsF5K5YlHSvv1sX2Odr', 'object': 'chat.completion', 'created': 1721504514, 'model': 'gpt-4o-2024-05-13', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': '### Critique and Suggestions\\n\\n**Critique:**\\n1. **Balance:**\\n   - The ad frame lacks vertical balance; the top part feels a bit cluttered because the header and engagement instruction are closely packed together.\\n\\n2. **Organization:**\\n   - The engagement instruction text below the header is well-organized but occupies too much vertical space, interrupting the flow to the central image.\\n   \\n3. **White Space:**\\n   - There’s too much white space above the header and too little below the engagement instruction, creating an imbalance.\\n\\n4. **Visual Appeal:**\\n   - The central image of the camera lens is compelling but somewhat disconnected from the instructional text above it.\\n\\n**Suggestions:**\\n1. **Header Positioning:**\\n   - Increase the white space above the header to give it more breathing room.\\n   - Example - Thumbnail: Header: 200 x 50\\n\\n2. **Engagement Instruction:**\\n   - Move the engagement instruction text closer to the camera lens image to create a more cohesive visual connection.\\n   - Example - Thumbnail: Engagement Instruction: 200 x 20\\n\\n3. **Central Image:**\\n   - Enlarge the central image slightly to make it the focal point and balance the space better.\\n   - Example - Thumbnail: Central Image: 200 x 150\\n\\n**Thumbnail Example:**\\n```\\n  _________________ (200 x 50) Header\\n \\n  _________(200 x 20) Engagement Instruction\\n\\n  _________('}, 'logprobs': None, 'finish_reason': 'length'}], 'usage': {'prompt_tokens': 729, 'completion_tokens': 300, 'total_tokens': 1029}, 'system_fingerprint': 'fp_18cc0f1fa0'}\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def encode_image(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Encodes an image file to a base64 string.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Base64 encoded string of the image.\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def describe_image(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Describes an image by sending it to the GPT-4o API and getting the description.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "    - str: Description of the image.\n",
    "    \"\"\"\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {openai_api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                      \"type\": \"text\", \n",
    "                      \"text\": f\"\"\"\n",
    "                        What’s in this image? You are a design critic. \n",
    "                        Your task is to evaluate the composition of an ad frame and suggest improvements based on design principles. \n",
    "                        Consider balance, organization, use of white space, and visual appeal.\n",
    "                        You shall provide your response with concise feedback on critic and suggest improvements and must provide better positioning of elements like this thumbnail: 200x300\n",
    "                        Be concise, do not exceed 300 tokens.\n",
    "                        These below are the features of the assets composing the adframe, use this to make informed suggestions. \n",
    "                        {summary}\n",
    "                        \"\"\"\n",
    "                    },\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    response_data = response.json()\n",
    "    print(response_data)\n",
    "    return response_data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\")\n",
    "\n",
    "description = describe_image(\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/composed_image_frame.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Critique and Suggestions\n",
      "\n",
      "**Critique:**\n",
      "1. **Balance:**\n",
      "   - The ad frame lacks vertical balance; the top part feels a bit cluttered because the header and engagement instruction are closely packed together.\n",
      "\n",
      "2. **Organization:**\n",
      "   - The engagement instruction text below the header is well-organized but occupies too much vertical space, interrupting the flow to the central image.\n",
      "   \n",
      "3. **White Space:**\n",
      "   - There’s too much white space above the header and too little below the engagement instruction, creating an imbalance.\n",
      "\n",
      "4. **Visual Appeal:**\n",
      "   - The central image of the camera lens is compelling but somewhat disconnected from the instructional text above it.\n",
      "\n",
      "**Suggestions:**\n",
      "1. **Header Positioning:**\n",
      "   - Increase the white space above the header to give it more breathing room.\n",
      "   - Example - Thumbnail: Header: 200 x 50\n",
      "\n",
      "2. **Engagement Instruction:**\n",
      "   - Move the engagement instruction text closer to the camera lens image to create a more cohesive visual connection.\n",
      "   - Example - Thumbnail: Engagement Instruction: 200 x 20\n",
      "\n",
      "3. **Central Image:**\n",
      "   - Enlarge the central image slightly to make it the focal point and balance the space better.\n",
      "   - Example - Thumbnail: Central Image: 200 x 150\n",
      "\n",
      "**Thumbnail Example:**\n",
      "```\n",
      "  _________________ (200 x 50) Header\n",
      " \n",
      "  _________(200 x 20) Engagement Instruction\n",
      "\n",
      "  _________(\n"
     ]
    }
   ],
   "source": [
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "Compose an AD Frame with the dimensions 600x500 for StoryBoard\n",
      "This is the concept. Place the header image at the top-left corner.\n",
      "Place the engagement instruction just below the logo in the header image but on the header image.\n",
      "Place the thumbnail below the header image.\n",
      "\n",
      "These are the features of the different assets separately. Use them to compose the AD Frame.\n",
      "{'header': {'image_role': 'header', 'image_path': '/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/header.jpg', 'dimensions': (600, 200), 'text_in_image_with_location': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}, 'has_transparency': False}, 'engagement_instruction': {'image_role': 'engagement_instruction', 'image_path': '/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/engagement_instruction_1.png', 'dimensions': (380, 63), 'text_in_image_with_location': {'TAP': (0, 1, 64, 28), 'THE': (75, 1, 140, 28), 'SCREEN': (152, 0, 293, 29), 'to': (0, 40, 21, 58), 'find': (27, 36, 65, 58), 'the': (73, 36, 106, 58), 'nearest': (114, 40, 192, 58), 'Lexus': (200, 36, 261, 58), 'dealership': (268, 36, 380, 63)}, 'has_transparency': True}, 'thumbnail': {'image_role': 'thumbnail', 'image_path': '/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/thumbnail.jpg', 'dimensions': (600, 300), 'text_in_image_with_location': {}, 'has_transparency': False}}\n",
      "\n",
      "The path to the assets folder is /home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/\n",
      "\n",
      "Use the assets path and the image names to get the image path\n",
      "\n",
      "The output path is the data folder can be derived from assets path with the name composed_image_frame.jpg\n",
      "\n",
      "Return 'TERMINATE' when the task is done.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: image_composition_agent\n",
      "\u001b[0m\n",
      "\u001b[33mimage_composition_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function call: functions_compose_ad_frame *****\u001b[0m\n",
      "Arguments: \n",
      "{\"frame_width\":600,\"frame_height\":500,\"elements\":[{\"image_path\":\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/header.jpg\",\"position\":[0,0],\"size\":[600,200],\"has_background\":true},{\"image_path\":\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/engagement_instruction_1.png\",\"position\":[110,140],\"size\":[380,63],\"has_background\":false},{\"image_path\":\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/thumbnail.jpg\",\"position\":[0,200],\"size\":[600,300],\"has_background\":true}],\"output_path\":\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/composed_image_frame.jpg\"}\n",
      "\u001b[32m***************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function (functions_compose_ad_frame) *****\u001b[0m\n",
      "Error: Function functions_compose_ad_frame not found.\n",
      "\u001b[32m***********************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: image_composition_agent\n",
      "\u001b[0m\n",
      "\u001b[33mimage_composition_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function call: compose_ad_frame *****\u001b[0m\n",
      "Arguments: \n",
      "{\"frame_width\":600,\"frame_height\":500,\"elements\":[{\"image_path\":\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/header.jpg\",\"position\":[0,0],\"size\":[600,200],\"has_background\":true},{\"image_path\":\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/engagement_instruction_1.png\",\"position\":[110,140],\"size\":[380,63],\"has_background\":false},{\"image_path\":\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/thumbnail.jpg\",\"position\":[0,200],\"size\":[600,300],\"has_background\":true}],\"output_path\":\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/composed_image_frame.jpg\"}\n",
      "\u001b[32m*****************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION compose_ad_frame...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function (compose_ad_frame) *****\u001b[0m\n",
      "/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/composed_image_frame.jpg\n",
      "\u001b[32m*************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: image_critic_agent\n",
      "\u001b[0m\n",
      "\u001b[33mimage_critic_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Suggested function call: get_frame_features *****\u001b[0m\n",
      "Arguments: \n",
      "{\"frame_path\":\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/composed_image_frame.jpg\",\"assets_path\":\"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/\"}\n",
      "\u001b[32m*******************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n",
      "\u001b[35m\n",
      ">>>>>>>> EXECUTING FUNCTION get_frame_features...\u001b[0m\n",
      "\u001b[33mUser\u001b[0m (to chat_manager):\n",
      "\n",
      "\u001b[32m***** Response from calling function (get_frame_features) *****\u001b[0m\n",
      "{'frame_features': {'frame_path': '/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/composed_image_frame.jpg', 'ad_frame_dimensions': (600, 500), 'text_bounded_box_format': ('left', 'top', 'right', 'bottom'), 'text_bounding_boxes': {'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90), 'TAP': (1, 101, 65, 128), 'THE': (76, 101, 141, 128), 'SCREEN': (153, 100, 294, 129), 'to': (1, 140, 22, 158), 'find': (28, 136, 66, 158), 'the': (74, 136, 107, 158), 'nearest': (115, 140, 193, 158), 'Lexus': (201, 136, 262, 158), 'dealership': (269, 136, 381, 163)}, 'elements': {'header': {'image_path': '/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854//header.jpg', 'position': (0, 0), 'size': (600, 200), 'text_in_image': ['Ovexus', 'L/CERTIFIED', 'BY', 'LEXUS'], 'has_background': True}, 'engagement_instruction': {'image_path': '/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854//engagement_instruction_1.png', 'position': (0, 100), 'size': (380, 63), 'text_in_image': ['TAP', 'THE', 'SCREEN', 'to', 'find', 'the', 'nearest', 'Lexus', 'dealership'], 'has_background': False}, 'thubmnail': {'image_path': '/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854//thumbnail.jpg', 'position': (0, 200), 'size': (600, 300), 'text_in_image': {}, 'has_background': True}}}}\n",
      "\u001b[32m***************************************************************\u001b[0m\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: image_critic_agent\n",
      "\u001b[0m\n",
      "\u001b[33mimage_critic_agent\u001b[0m (to chat_manager):\n",
      "\n",
      "The composed AD Frame has the following features:\n",
      "\n",
      "1. **Header**:\n",
      "   - Positioned at the top-left corner (0, 0).\n",
      "   - Dimensions: 600x200.\n",
      "   - Text Elements: \"Ovexus\", \"L/CERTIFIED\", \"BY\", \"LEXUS\".\n",
      "\n",
      "2. **Engagement Instruction**:\n",
      "   - Positioned below the header image on the header image at (0, 100).\n",
      "   - Dimensions: 380x63.\n",
      "   - Text Elements: \"TAP\", \"THE\", \"SCREEN\", \"to\", \"find\", \"the\", \"nearest\", \"Lexus\", \"dealership\".\n",
      "\n",
      "3. **Thumbnail**:\n",
      "   - Positioned below the header image at (0, 200).\n",
      "   - Dimensions: 600x300.\n",
      "   \n",
      "The frame seems to be composed correctly with no overlapping elements. The text and images appear to be well-aligned and appropriately positioned.\n",
      "\n",
      "All good.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: User\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "assets_path = '/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/'\n",
    "system_instruction = f\"\"\"\n",
    "The path to the assets folder is {assets_path}\n",
    "\n",
    "Use the assets path and the image names to get the image path\n",
    "\n",
    "The output path is the data folder can be derived from assets path with the name composed_image_frame.jpg\n",
    "\n",
    "Return 'TERMINATE' when the task is done.\n",
    "\"\"\"\n",
    "\n",
    "user_message = f\"\"\"\n",
    "Compose an AD Frame with the dimensions 600x500 for StoryBoard\n",
    "This is the concept. Place the header image at the top-left corner.\n",
    "Place the engagement instruction just below the logo in the header image but on the header image.\n",
    "Place the thumbnail below the header image.\n",
    "\n",
    "These are the features of the different assets separately. Use them to compose the AD Frame.\n",
    "{get_all_assets_features}\n",
    "\"\"\"\n",
    "\n",
    "final_message = user_message + system_instruction\n",
    "\n",
    "chat_result = user_proxy.initiate_chat(manager, message=final_message, max_turns=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
