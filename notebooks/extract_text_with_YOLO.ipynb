{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/bfbf7a2b7ac635e67877b1ab87fd6629/_preview.png: 640x448 2 kites, 234.8ms\n",
      "Speed: 4.0ms preprocess, 234.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/.venv/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| game_id                          | preview_link                                                                                                                                            | ER       | CTR       | objects   | colors                                                                        | positions                                                          | text                                 |\n",
      "|:---------------------------------|:--------------------------------------------------------------------------------------------------------------------------------------------------------|:---------|:----------|:----------|:------------------------------------------------------------------------------|:-------------------------------------------------------------------|:-------------------------------------|\n",
      "| bfbf7a2b7ac635e67877b1ab87fd6629 | https://s3.us-east-1.amazonaws.com/a.futureadlabs.com-us-east-1-backup/us-east-1/games/bfbf7a2b7ac635e67877b1ab87fd6629/b7a604b3b08f0862ef0e/index.html | 0.209269 | 0.0584383 | ['kite']  | [[70, 111, 75], [254, 254, 254], [1, 1, 1], [195, 195, 195], [132, 132, 132]] | [[tensor(0.4353), tensor(0.8288), tensor(0.5873), tensor(0.9489)]] | Ovexus                               |\n",
      "|                                  |                                                                                                                                                         |          |           |           |                                                                               |                                                                    | L/CERTIFIED BY LEXUS                 |\n",
      "|                                  |                                                                                                                                                         |          |           |           |                                                                               |                                                                    |                                      |\n",
      "|                                  |                                                                                                                                                         |          |           |           |                                                                               |                                                                    | TAP THE SCREEN                       |\n",
      "|                                  |                                                                                                                                                         |          |           |           |                                                                               |                                                                    |                                      |\n",
      "|                                  |                                                                                                                                                         |          |           |           |                                                                               |                                                                    | to find the nearest Lexus dealership |\n",
      "|                                  |                                                                                                                                                         |          |           |           |                                                                               |                                                                    |                                      |\n",
      "|                                  |                                                                                                                                                         |          |           |           |                                                                               |                                                                    | (iF                                  |\n"
     ]
    }
   ],
   "source": [
    "# !pip install ultralytics pytesseract\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import pytesseract\n",
    "\n",
    "# Load the performance data\n",
    "df_performance = pd.read_csv('data/performance_data.csv')\n",
    "df_performance = df_performance.head(1)  # For demonstration purposes\n",
    "\n",
    "# Create an empty dictionary to store the results\n",
    "results = {}\n",
    "\n",
    "# Iterate through each row in the dataframe\n",
    "for index, row in df_performance.iterrows():\n",
    "    game_id = row['game_id']\n",
    "    image_path = f'data/Assets/{game_id}/_preview.png'\n",
    "\n",
    "    # Check if the image file exists\n",
    "    if os.path.exists(image_path):\n",
    "        # Load the image using Pillow\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        # Object Identification\n",
    "        model = YOLO('yolov8n.pt')  # Load a YOLOv8 model (you might need to download it first)\n",
    "        results_yolo = model(image_path)\n",
    "        class_names = [model.names[int(result.boxes.cls[0])] for result in results_yolo]\n",
    "        results[game_id] = {'objects': class_names}\n",
    "\n",
    "        # Color Identification\n",
    "        img_rgb = img.convert('RGB')\n",
    "        img_array = np.array(img_rgb).reshape(-1, 3)\n",
    "        kmeans = KMeans(n_clusters=5, random_state=0).fit(img_array)\n",
    "        dominant_colors = kmeans.cluster_centers_.astype(int)\n",
    "        results[game_id]['colors'] = dominant_colors.tolist()\n",
    "\n",
    "        # Position Extraction\n",
    "        positions = []\n",
    "        for result in results_yolo:\n",
    "            x1, y1, x2, y2 = result.boxes.xyxy[0]\n",
    "            positions.append([x1 / img.width, y1 / img.height, x2 / img.width, y2 / img.height])\n",
    "        results[game_id]['positions'] = positions\n",
    "\n",
    "        # Character Recognition\n",
    "        text = pytesseract.image_to_string(img)\n",
    "        results[game_id]['text'] = text\n",
    "\n",
    "# Create a new dataframe from the results dictionary\n",
    "df_features = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "# Merge the new dataframe with the original dataframe on the `game_id` column\n",
    "merged_df = df_performance.merge(df_features, left_on='game_id', right_index=True, how='left')\n",
    "\n",
    "# Display the first 5 rows of the merged dataframe\n",
    "print(merged_df.head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def extract_text_with_positions(image_path):\n",
    "    \"\"\"\n",
    "    Extracts text from an image and returns a dictionary mapping the text to its position (bounding box).\n",
    "\n",
    "    Args:\n",
    "        image_path: The path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary where keys are text strings and values are lists of bounding box coordinates\n",
    "        in the format [x1, y1, x2, y2] (normalized to image width and height).\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the image file does not exist.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "\n",
    "    # Load image\n",
    "    img = Image.open(image_path)\n",
    "    img_width, img_height = img.size\n",
    "\n",
    "    # Text Detection and OCR (Optical Character Recognition)\n",
    "    model = YOLO('yolov8n.pt') \n",
    "    results_yolo = model(image_path)  \n",
    "    \n",
    "    text_positions = {}\n",
    "    for result in results_yolo:\n",
    "        if result.boxes.cls[0] == 3:  # Filter for 'text' class in YOLOv8 (adjust if needed)\n",
    "            x1, y1, x2, y2 = result.boxes.xyxy[0]  # Extract coordinates\n",
    "            cropped_image = img.crop((x1, y1, x2, y2))\n",
    "            text = pytesseract.image_to_string(cropped_image)  # Perform OCR on cropped region\n",
    "            if text:\n",
    "                normalized_coords = [x1 / img_width, y1 / img_height, x2 / img_width, y2 / img_height]\n",
    "                text_positions[text.strip()] = normalized_coords  # Add to dictionary\n",
    "\n",
    "    return text_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/_preview.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 324MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/_preview.png: 544x640 1 kite, 289.3ms\n",
      "Speed: 4.3ms preprocess, 289.3ms inference, 1.4ms postprocess per image at shape (1, 3, 544, 640)\n"
     ]
    }
   ],
   "source": [
    "text_positions = extract_text_with_positions(image_path)\n",
    "for text, position in text_positions.items():\n",
    "    print(f\"Text: '{text}', Position: {position}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(text_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90), 'TAP': (50, 115, 114, 142), 'THE': (125, 115, 190, 142), 'SCREEN': (202, 114, 343, 143), 'to': (50, 154, 71, 172), 'find': (77, 150, 115, 172), 'the': (123, 150, 156, 172), 'nearest': (164, 154, 242, 172), 'Lexus': (250, 150, 311, 172), 'dealership': (318, 150, 430, 177)}\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text_with_positions(image_path):\n",
    "    # Load the image using Pillow\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Use pytesseract to get the bounding boxes\n",
    "    data = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "\n",
    "    # Initialize the result dictionary\n",
    "    text_positions = {}\n",
    "\n",
    "    # Iterate through the data to extract text and their positions\n",
    "    n_boxes = len(data['level'])\n",
    "    for i in range(n_boxes):\n",
    "        if data['text'][i].strip():  # Check if the text is not empty\n",
    "            text = data['text'][i]\n",
    "            x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "            # Store the position as a tuple (left, top, right, bottom)\n",
    "            text_positions[text] = (x, y, x + w, y + h)\n",
    "\n",
    "    return text_positions\n",
    "\n",
    "# Example usage\n",
    "result = extract_text_with_positions(image_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ovexus': (50, 27, 245, 60), 'L/CERTIFIED': (50, 77, 161, 90), 'BY': (174, 77, 198, 90), 'LEXUS': (211, 77, 283, 90)}\n"
     ]
    }
   ],
   "source": [
    "header_image_path = \"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/header.jpg\"\n",
    "result = extract_text_with_positions(header_image_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "thumbnail_image_path = \"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/thumbnail.jpg\"\n",
    "result = extract_text_with_positions(thumbnail_image_path)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TAP': (0, 1, 64, 28), 'THE': (75, 1, 140, 28), 'SCREEN': (152, 0, 293, 29), 'to': (0, 40, 21, 58), 'find': (27, 36, 65, 58), 'the': (73, 36, 106, 58), 'nearest': (114, 40, 192, 58), 'Lexus': (200, 36, 261, 58), 'dealership': (268, 36, 380, 63)}\n"
     ]
    }
   ],
   "source": [
    "engagement_instruction = \"/home/hillary_kipkemoi/Automated-Storyboard-Synthesis-Digital-Advertising/data/Assets/0a22f881b77f00220f2034c21a18b854/engagement_instruction_1.png\"\n",
    "result = extract_text_with_positions(engagement_instruction)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compose a frame that is not aligned properly for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
